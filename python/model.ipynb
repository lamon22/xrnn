{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch flask flask_cors onnx onnxscript torchvision onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55c99d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46858c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteMLP(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_nodes=3,\n",
    "            hidden_layer_sizes=[10,7,5,5],\n",
    "            output_nodes=10,    \n",
    "    ):\n",
    "\n",
    "        super(LiteMLP, self).__init__()\n",
    "\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.rebuild_model()\n",
    "\n",
    "    def rebuild_model(\n",
    "            self,\n",
    "    ):\n",
    "        \n",
    "        layers = OrderedDict()\n",
    "        all_sizes = [self.input_nodes] + self.hidden_layer_sizes + [self.output_nodes]\n",
    "\n",
    "        for i in range(len(all_sizes) - 1):\n",
    "            layers[f'linear_{i}'] = nn.Linear(all_sizes[i], all_sizes[i+1])\n",
    "\n",
    "            if i < len(all_sizes) - 2:\n",
    "                layers[f'activation_{i}'] = nn.ReLU()\n",
    "\n",
    "        self.backbone = nn.Sequential(layers)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x,\n",
    "    ):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def add_node(\n",
    "            self,\n",
    "            layer_index,\n",
    "            num_nodes_to_add=1,\n",
    "    ):\n",
    "\n",
    "        num_linear_layers = len(self.hidden_layer_sizes) + 1\n",
    "        if not (0 <= layer_index < num_linear_layers):\n",
    "            raise ValueError(f\"layer_index must be between 0 and {num_linear_layers - 1}\")\n",
    "        \n",
    "        if num_nodes_to_add < 1:\n",
    "            return\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if layer_index < len(self.hidden_layer_sizes):\n",
    "                current_linear_idx = layer_index * 2\n",
    "                next_linear_idx = (layer_index + 1) * 2\n",
    "\n",
    "                self.hidden_layer_sizes[layer_index] += num_nodes_to_add\n",
    "                \n",
    "                old_layer_current = self.backbone[current_linear_idx]\n",
    "                old_layer_next = self.backbone[next_linear_idx]\n",
    "                \n",
    "                new_size = old_layer_current.out_features + num_nodes_to_add\n",
    "                new_layer_current = nn.Linear(old_layer_current.in_features, new_size)\n",
    "                new_layer_next = nn.Linear(new_size, old_layer_next.out_features)\n",
    "\n",
    "                new_layer_current.weight.data[:-num_nodes_to_add, :] = old_layer_current.weight.data\n",
    "                new_layer_current.bias.data[:-num_nodes_to_add] = old_layer_current.bias.data\n",
    "                \n",
    "                new_layer_next.weight.data[:, :-num_nodes_to_add] = old_layer_next.weight.data\n",
    "                new_layer_next.bias.data.copy_(old_layer_next.bias.data)\n",
    "\n",
    "                nn.init.zeros_(new_layer_current.weight.data[-num_nodes_to_add:, :])\n",
    "                nn.init.zeros_(new_layer_current.bias.data[-num_nodes_to_add:])\n",
    "                nn.init.zeros_(new_layer_next.weight.data[:, -num_nodes_to_add:])\n",
    "                \n",
    "                self.backbone[current_linear_idx] = new_layer_current\n",
    "                self.backbone[next_linear_idx] = new_layer_next\n",
    "            else:\n",
    "                output_layer_idx = layer_index * 2\n",
    "                self.output_nodes += num_nodes_to_add\n",
    "                \n",
    "                old_output_layer = self.backbone[output_layer_idx]\n",
    "                new_output_layer = nn.Linear(old_output_layer.in_features, self.output_nodes)\n",
    "                \n",
    "                new_output_layer.weight.data[:-num_nodes_to_add, :] = old_output_layer.weight.data\n",
    "                new_output_layer.bias.data[:-num_nodes_to_add] = old_output_layer.bias.data\n",
    "                nn.init.zeros_(new_output_layer.weight.data[-num_nodes_to_add:, :])\n",
    "                nn.init.zeros_(new_output_layer.bias.data[-num_nodes_to_add:])\n",
    "                \n",
    "                self.backbone[output_layer_idx] = new_output_layer\n",
    "\n",
    "    def remove_node(\n",
    "            self,\n",
    "            layer_index,\n",
    "            num_nodes_to_remove=1,\n",
    "    ):\n",
    "        \n",
    "        num_linear_layers = len(self.hidden_layer_sizes) + 1\n",
    "        if not (0 <= layer_index < num_linear_layers):\n",
    "            raise ValueError(f\"layer_index must be between 0 and {num_linear_layers - 1}\")\n",
    "        \n",
    "        if num_nodes_to_remove < 1:\n",
    "            return\n",
    "        \n",
    "        node_indices_to_remove = list(range(num_nodes_to_remove))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if layer_index < len(self.hidden_layer_sizes):\n",
    "                if self.hidden_layer_sizes[layer_index] <= num_nodes_to_remove:\n",
    "                    return \n",
    "\n",
    "                current_linear_idx = layer_index * 2\n",
    "                next_linear_idx = (layer_index + 1) * 2\n",
    "                \n",
    "                old_layer_current = self.backbone[current_linear_idx]\n",
    "                old_layer_next = self.backbone[next_linear_idx]\n",
    "                \n",
    "                self.hidden_layer_sizes[layer_index] -= num_nodes_to_remove\n",
    "                \n",
    "                new_size = old_layer_current.out_features - num_nodes_to_remove\n",
    "                new_layer_current = nn.Linear(old_layer_current.in_features, new_size)\n",
    "                new_layer_next = nn.Linear(new_size, old_layer_next.out_features)\n",
    "                \n",
    "                mask = torch.ones(old_layer_current.out_features, dtype=torch.bool)\n",
    "                mask[node_indices_to_remove] = False\n",
    "                \n",
    "                new_layer_current.weight.data = old_layer_current.weight.data[mask, :]\n",
    "                new_layer_current.bias.data = old_layer_current.bias.data[mask]\n",
    "                \n",
    "                new_layer_next.weight.data = old_layer_next.weight.data[:, mask]\n",
    "                new_layer_next.bias.data.copy_(old_layer_next.bias.data)\n",
    "\n",
    "                self.backbone[current_linear_idx] = new_layer_current\n",
    "                self.backbone[next_linear_idx] = new_layer_next\n",
    "                \n",
    "            else:\n",
    "                if self.output_nodes <= num_nodes_to_remove:\n",
    "                    return\n",
    "\n",
    "                output_layer_idx = layer_index * 2\n",
    "                old_output_layer = self.backbone[output_layer_idx]\n",
    "                \n",
    "                self.output_nodes -= num_nodes_to_remove\n",
    "\n",
    "                new_output_layer = nn.Linear(old_output_layer.in_features, self.output_nodes)\n",
    "                \n",
    "                mask = torch.ones(old_output_layer.out_features, dtype=torch.bool)\n",
    "                mask[node_indices_to_remove] = False\n",
    "                \n",
    "                new_output_layer.weight.data = old_output_layer.weight.data[mask, :]\n",
    "                new_output_layer.bias.data = old_output_layer.bias.data[mask]\n",
    "\n",
    "                self.backbone[output_layer_idx] = new_output_layer\n",
    "\n",
    "    def add_layer(\n",
    "            self, \n",
    "            layer_index, \n",
    "            new_layer_size=16\n",
    "    ):\n",
    "\n",
    "        num_hidden_layers = len(self.hidden_layer_sizes)\n",
    "        if not (0 <= layer_index <= num_hidden_layers):\n",
    "            raise ValueError(f\"layer_index for add_layer must be between 0 and {num_hidden_layers}.\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            all_modules = list(self.backbone.children())\n",
    "\n",
    "            if layer_index == 0:\n",
    "                prev_out_features = self.input_nodes\n",
    "                next_layer = all_modules[0]\n",
    "            else:\n",
    "                prev_layer = all_modules[(layer_index - 1) * 2]\n",
    "                prev_out_features = prev_layer.out_features\n",
    "\n",
    "                if layer_index < num_hidden_layers:\n",
    "                    next_layer = all_modules[layer_index * 2]\n",
    "                else:\n",
    "                    next_layer = all_modules[-1]\n",
    "            \n",
    "            new_layer = nn.Linear(prev_out_features, new_layer_size)\n",
    "            new_relu = nn.ReLU()\n",
    "\n",
    "            old_next_layer_out_features = next_layer.out_features\n",
    "            modified_next_layer = nn.Linear(new_layer_size, old_next_layer_out_features)\n",
    "\n",
    "            insert_idx = layer_index * 2\n",
    "            \n",
    "            all_modules.insert(insert_idx, new_layer)\n",
    "            all_modules.insert(insert_idx + 1, new_relu)\n",
    "            \n",
    "            old_next_layer_idx = insert_idx + 2 \n",
    "            all_modules[old_next_layer_idx] = modified_next_layer\n",
    "\n",
    "            self.hidden_layer_sizes.insert(layer_index, new_layer_size)\n",
    "            \n",
    "            new_layers_dict = OrderedDict()\n",
    "            linear_count = 0\n",
    "            relu_count = 0\n",
    "            for module in all_modules:\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    new_layers_dict[f'linear_{linear_count}'] = module\n",
    "                    linear_count += 1\n",
    "                elif isinstance(module, nn.ReLU):\n",
    "                    new_layers_dict[f'relu_{relu_count}'] = module\n",
    "                    relu_count += 1\n",
    "            \n",
    "            self.backbone = nn.Sequential(new_layers_dict)\n",
    "\n",
    "    def remove_layer(self, layer_index):\n",
    "\n",
    "        num_hidden_layers = len(self.hidden_layer_sizes)\n",
    "        if not (0 <= layer_index < num_hidden_layers):\n",
    "            raise ValueError(f\"layer_index for remove_layer must be between 0 and {num_hidden_layers - 1}.\")\n",
    "        if num_hidden_layers <= 1:\n",
    "            return\n",
    "    \n",
    "        self.hidden_layer_sizes.pop(layer_index)\n",
    "        self.rebuild_model()\n",
    "\n",
    "    def change_activation(\n",
    "            self,\n",
    "            layer_index,\n",
    "            new_activation_name,\n",
    "    ):\n",
    "\n",
    "        supported_activations = {\n",
    "            'relu': nn.ReLU,\n",
    "            'sigmoid': nn.Sigmoid,\n",
    "            'tanh': nn.Tanh,\n",
    "            'leakyrelu': nn.LeakyReLU\n",
    "        }\n",
    "        \n",
    "        if not (0 <= layer_index < len(self.hidden_layer_sizes)):\n",
    "            raise ValueError(f\"layer_index must be between 0 and {len(self.hidden_layer_sizes) - 1}.\")\n",
    "        \n",
    "        activation_key = new_activation_name.lower()\n",
    "        activation_layer_name = f'activation_{layer_index}'\n",
    "        \n",
    "        if activation_layer_name not in self.backbone._modules:\n",
    "            return\n",
    "            \n",
    "        NewActivationClass = supported_activations[activation_key]\n",
    "        new_activation_layer = NewActivationClass()\n",
    "        \n",
    "        self.backbone._modules[activation_layer_name] = new_activation_layer\n",
    "\n",
    "    def get_architecture(\n",
    "            self,\n",
    "    ):\n",
    "        \n",
    "        activations = []\n",
    "        for i in range(len(self.hidden_layer_sizes)):\n",
    "            activation_layer_name = f'activation_{i}'\n",
    "            if activation_layer_name in self.backbone._modules:\n",
    "                layer = self.backbone._modules[activation_layer_name]\n",
    "                activations.append(layer.__class__.__name__)\n",
    "            else:\n",
    "                activations.append(\"None\")\n",
    "\n",
    "        return {\n",
    "            \"input_nodes\": self.input_nodes,\n",
    "            \"hidden_layer_sizes\": self.hidden_layer_sizes,\n",
    "            \"output_nodes\": self.output_nodes,\n",
    "            \"activations\": activations,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41af9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_to_onnx(model, path):\n",
    "\n",
    "    dummy_input = torch.randn(1, model.input_nodes)\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        path,\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        do_constant_folding=False,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e004fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(onnx_path, state_dict_path):\n",
    "\n",
    "    if os.path.exists(state_dict_path):\n",
    "\n",
    "        state_dict = torch.load(state_dict_path)\n",
    "        input_nodes = state_dict['backbone.linear_0.weight'].shape[1]\n",
    "        output_nodes = state_dict[list(state_dict.keys())[-1]].shape[0]\n",
    "        hidden_layer_sizes = []\n",
    "\n",
    "        num_hidden_layers = (len(state_dict.keys()) // 2) -1\n",
    "        for i in range(num_hidden_layers):\n",
    "            hidden_layer_sizes.append(state_dict[f'backbone.linear_{i}.weight'].shape[0])\n",
    "            \n",
    "        model = LiteMLP(input_nodes, hidden_layer_sizes, output_nodes)\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        model = LiteMLP()\n",
    "        \n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156d052",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5df16fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d3/31wmzwx14ns4qrv1k_kmq9lm0000gn/T/ipykernel_19398/1850939294.py:5: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.5:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [22/Aug/2025 23:24:55] \"GET /get_architecture HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:40] \"GET /get_architecture HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:41] \"POST /get_node_details HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:44] \"POST /get_node_details HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:45] \"POST /get_node_details HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:47] \"POST /get_node_details HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Aug/2025 23:28:48] \"POST /get_node_details HTTP/1.1\" 200 -\n",
      "192.168.1.19 - - [22/Aug/2025 23:32:04] \"GET /get_architecture HTTP/1.1\" 200 -\n",
      "192.168.1.19 - - [22/Aug/2025 23:33:53] \"GET /get_architecture HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "onnx_path = \"lite_mlp.onnx\"\n",
    "state_dict_path = \"lite_mlp.pth\"\n",
    "\n",
    "model = load_model(onnx_path, state_dict_path)\n",
    "model.eval()\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/get_architecture\", methods=[\"GET\"])\n",
    "def get_architecture():\n",
    "    return jsonify({\"status\": \"success\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/get_model\", methods=[\"GET\"])\n",
    "def get_model():\n",
    "    try:\n",
    "        return send_file(\n",
    "                    onnx_path, \n",
    "                    mimetype=\"application/octet-stream\"\n",
    "               )\n",
    "    except:\n",
    "        return jsonify({\"error\": \"File not found\"}), 404\n",
    "    \n",
    "@app.route(\"/add_node\", methods=[\"POST\"])\n",
    "def add_node():\n",
    "    data = request.json\n",
    "    layer_index = data[\"layer_index\"]\n",
    "    num_nodes = data.get(\"num_nodes\", 1) \n",
    "    model.add_node(layer_index, num_nodes)\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    return jsonify({\"status\": \"success\", \"message\": f\"{num_nodes} node(s) added\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/remove_node\", methods=[\"POST\"])\n",
    "def remove_node():\n",
    "    data = request.json\n",
    "    layer_index = data[\"layer_index\"]\n",
    "    num_nodes = data.get(\"num_nodes\", 1)    \n",
    "    model.remove_node(layer_index, num_nodes)\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    return jsonify({\"status\": \"success\", \"message\": f\"{num_nodes} node(s) removed\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/add_layer\", methods=[\"POST\"])\n",
    "def add_layer():\n",
    "    data = request.json\n",
    "    model.add_layer(data[\"layer_index\"], data[\"new_layer_size\"])\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    return jsonify({\"status\": \"success\", \"message\": \"layer added\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/remove_layer\", methods=[\"POST\"])\n",
    "def remove_layer():\n",
    "    data = request.json\n",
    "    model.remove_layer(data[\"layer_index\"])\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    return jsonify({\"status\": \"success\", \"message\": \"layer removed\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/change_activation\", methods=[\"POST\"])\n",
    "def change_activation():\n",
    "    data = request.json\n",
    "    model.change_activation(data[\"layer_index\"], data[\"new_activation_name\"])\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    export_model_to_onnx(model, onnx_path)\n",
    "    return jsonify({\"status\": \"success\", \"message\": \"activation changed\", \"architecture\": model.get_architecture()})\n",
    "\n",
    "@app.route(\"/forward_pass\", methods=[\"POST\"])\n",
    "def forward_pass():\n",
    "    data = request.json\n",
    "    input_data = data.get(\"input_data\", [0.5] * model.input_nodes)\n",
    "    \n",
    "    activations = []\n",
    "    hooks = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach())\n",
    "\n",
    "    for layer in model.backbone.children():\n",
    "        hook = layer.register_forward_hook(hook_fn)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    input_tensor = torch.FloatTensor([input_data])\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    final_activations = [input_data]\n",
    "    all_activations_data = [act.tolist()[0] for act in activations]\n",
    "    \n",
    "    num_hidden_layers = len(model.hidden_layer_sizes)\n",
    "    for i in range(num_hidden_layers):\n",
    "        activation_output_idx = i * 2 + 1\n",
    "        if activation_output_idx < len(all_activations_data):\n",
    "            final_activations.append(all_activations_data[activation_output_idx])\n",
    "    \n",
    "    if all_activations_data:\n",
    "        final_activations.append(all_activations_data[-1])\n",
    "\n",
    "\n",
    "    return jsonify({\"status\": \"success\", \"activations\": final_activations})\n",
    "\n",
    "@app.route(\"/get_node_details\", methods=[\"POST\"])\n",
    "def get_node_details():\n",
    "    data = request.json\n",
    "    layer_index = int(data[\"layer_index\"])\n",
    "    node_index = int(data[\"node_index\"])\n",
    "    \n",
    "    response_data = {\n",
    "        \"status\": \"success\",\n",
    "        \"weights\": [],\n",
    "        \"bias\": None\n",
    "    }\n",
    "    \n",
    "    if layer_index == 0:\n",
    "        response_data[\"status\"] = \"info\"\n",
    "        response_data[\"message\"] = \"Input layer nodes do not have weights or biases.\"\n",
    "        return jsonify(response_data)\n",
    "        \n",
    "    linear_layer_idx_in_backbone = (layer_index - 1) * 2\n",
    "    target_layer = model.backbone[linear_layer_idx_in_backbone]\n",
    "    weights = target_layer.weight.data[node_index, :].tolist()\n",
    "    bias = target_layer.bias.data[node_index].item()\n",
    "    \n",
    "    response_data[\"weights\"] = weights\n",
    "    response_data[\"bias\"] = bias\n",
    "    \n",
    "    return jsonify(response_data)\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
